{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "## 000) Project Information\n",
    "### _-- A) Data Source_\n",
    "### _-- B) Data Profile_\n",
    "### _-- C) My Questions_\n",
    "## 00) Notes on Dataset\n",
    "## 0) Import\n",
    "## 1) Data Understanding\n",
    "## 2) Data Preparation\n",
    "### _-- A) Data Wrangling & Subsetting_\n",
    "### _-- B) Data Consistency Checks_\n",
    "### _-- C) Derivations & Aggregations_\n",
    "## 3) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 000) Project Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _-- A) Data Source_\n",
    "- source: https://www.kaggle.com/usgs/earthquake-database\n",
    "- more on NEIC here: https://www.usgs.gov/natural-hazards/earthquake-hazards/national-earthquake-information-center-neic?qt-science_support_page_related_con=3#qt-science_support_page_related_con\n",
    "\n",
    "## Summary\n",
    "\n",
    "This data is collected by the National Earthquake Information Center (NEIC), a segment of The United States Geologic Survey which is a US government project and trustworthy source of data. Although \"survey\" is in the title, the data is collected automatically by electronic sources - namely \"through the operation of modern digital national and global seismograph networks\". \n",
    "\n",
    "__There are 21 variables contained in the dataset.__\n",
    "\n",
    "Continuous variables include:\n",
    "- Date\n",
    "- Time\n",
    "- Depth\n",
    "- Depth Error\n",
    "- Depth Seismic Stations\n",
    "- Magnitude\n",
    "- Magnitude Error\n",
    "- Magnitude Seismic Stations\n",
    "- Root Mean Square\n",
    "\n",
    "Categorical Variables include:\n",
    "- Type\n",
    "- Magnitude Type\n",
    "- Source\n",
    "- Location Source\n",
    "- Magnitude Source\n",
    "- Status\n",
    "\n",
    "The data is limited to 1965-2016, and only to seismic activity 5.5 and higher. Given these limitations, this data is still relevant to my purposes in learning about seismic phenomena. There is the potential for bias if any of the seismic sensors broke or stopped working. We will see as I examine the data.\n",
    "\n",
    "I my favorite sciences are biology and psychology. I was fascinated by dinosaurs as a kid, my parents bragged that I could name (and pronounce the name of) any dinosaur I saw. I also knew that the prehistoric world was shaped into one megacontinent called Pangea. \n",
    "\n",
    "![Pangea](pangea.gif)\n",
    "\n",
    "Continental drift shuffled the tectonic plates to new locations as time went on. That's how we ended up where we are today, with the Atlantic Ocean between smaller continents that were once one big continent. I think nature is super interesting and I'm hoping that by studying this dataset I can learn something new.\n",
    "\n",
    "__Other Background Info__\n",
    "- Earthquakes are caused when \"two blocks of crust ... slip past one another\".\n",
    "- \"A negative depth can sometimes be an artifact of the poor resolution for a shallow event\". Referring to the 'Depth' variable.\n",
    "- 'Azimuthal Gap' is the angle (in degrees) from another nearby seismic recording head. Variable may be irrevelant to my needs.\n",
    "- 'Horizontal Distance' is distance between waves from crest to crest (or trough to trough). AKA 'wavelength'.\n",
    "- 'Root Mean Square' is \"a measure of the imperfection of the fit of the estimator to the data\".\n",
    "\n",
    "source: https://www.usgs.gov/faqs/what-does-it-mean-earthquake-occurred-a-depth-0-km-how-can-earthquake-have-a-negative-depth?qt-news_science_products=0#qt-news_science_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _-- B) Data Profile_\n",
    "\n",
    "- See [link](https://drive.google.com/file/d/1jEP0bpTceud-6eQtGSS1q9Lz_nIM7VvX/view?usp=sharing)\n",
    "- Limitations & Ethics:\n",
    " - What laws should I be aware of regarding ethics of seismic data?\n",
    " - The EIC released this information publicly, but do the other organizations that helped gather this information consent to their information being available to the public?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _-- C) My Questions_\n",
    "- Where does most significant seismic activity occur? Can I identify any geologic patterns? (mountains, etc?)\n",
    "- When do earthquakes happen? Can I identify earthquake patterns across time? \n",
    "- Do earthquakes happen at a certain time of day? Year?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00) Notes on Dataset\n",
    "\n",
    "- original dataset has __23,412 rows & 21 columns__\n",
    "- first seismic event was on '01/01/1967'\n",
    "- most recent event was '12/30/2016'\n",
    "- the depth of an earthquake occurs beween 0-700 km\n",
    " - shallow earthquakes 0-70\n",
    " - intermediate 70-300\n",
    " - deep 300-700\n",
    "- range for latitude is -90 to 90\n",
    "- range for longitude is -180 to 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'/Users/sjpeterson76/Desktop/Seismic Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(os.path.join(path,'database.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23412, 21)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=df.columns.to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.tolist of Index(['Date', 'Time', 'Latitude', 'Longitude', 'Type', 'Depth', 'Depth Error',\n",
       "       'Depth Seismic Stations', 'Magnitude', 'Magnitude Type',\n",
       "       'Magnitude Error', 'Magnitude Seismic Stations', 'Azimuthal Gap',\n",
       "       'Horizontal Distance', 'Horizontal Error', 'Root Mean Square', 'ID',\n",
       "       'Source', 'Location Source', 'Magnitude Source', 'Status'],\n",
       "      dtype='object')>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23412 entries, 0 to 23411\n",
      "Data columns (total 21 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Date                        23412 non-null  object \n",
      " 1   Time                        23412 non-null  object \n",
      " 2   Latitude                    23412 non-null  float64\n",
      " 3   Longitude                   23412 non-null  float64\n",
      " 4   Type                        23412 non-null  object \n",
      " 5   Depth                       23412 non-null  float64\n",
      " 6   Depth Error                 4461 non-null   float64\n",
      " 7   Depth Seismic Stations      7097 non-null   float64\n",
      " 8   Magnitude                   23412 non-null  float64\n",
      " 9   Magnitude Type              23409 non-null  object \n",
      " 10  Magnitude Error             327 non-null    float64\n",
      " 11  Magnitude Seismic Stations  2564 non-null   float64\n",
      " 12  Azimuthal Gap               7299 non-null   float64\n",
      " 13  Horizontal Distance         1604 non-null   float64\n",
      " 14  Horizontal Error            1156 non-null   float64\n",
      " 15  Root Mean Square            17352 non-null  float64\n",
      " 16  ID                          23412 non-null  object \n",
      " 17  Source                      23412 non-null  object \n",
      " 18  Location Source             23412 non-null  object \n",
      " 19  Magnitude Source            23412 non-null  object \n",
      " 20  Status                      23412 non-null  object \n",
      "dtypes: float64(12), object(9)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Earthquake           23232\n",
       "Nuclear Explosion      175\n",
       "Explosion                4\n",
       "Rock Burst               1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MW     7722\n",
       "MWC    5669\n",
       "MB     3761\n",
       "MWB    2458\n",
       "MWW    1983\n",
       "MS     1702\n",
       "ML       77\n",
       "MWR      26\n",
       "MD        6\n",
       "MH        5\n",
       "Name: Magnitude Type, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Magnitude Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Magnitude Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What needs work?\n",
    "\n",
    "__Completed__\n",
    "- Remove variable(s): \n",
    " - 'Azimuthal Gap'\n",
    "- Columns need to be abbreviated and snake_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _-- A) Data Wrangling & Subsetting_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get visual for 'Type'\n",
    "\n",
    "type_bar=df['Type'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export 'Type' visual\n",
    "\n",
    "type_bar.figure.savefig(os.path.join(path,\n",
    "                                     'Visuals',\n",
    "                                     'type_bar.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop 'Azimuthal Gap'\n",
    "df.shape # Get column count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['Azimuthal Gap']) # Drop 'Azimuthal Gap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23412, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # Get column count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename columns as abbreviations in snake_case\n",
    "cols=df.columns.to_list() # Get column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Time',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'Type',\n",
       " 'Depth',\n",
       " 'Depth Error',\n",
       " 'Depth Seismic Stations',\n",
       " 'Magnitude',\n",
       " 'Magnitude Type',\n",
       " 'Magnitude Error',\n",
       " 'Magnitude Seismic Stations',\n",
       " 'Horizontal Distance',\n",
       " 'Horizontal Error',\n",
       " 'Root Mean Square',\n",
       " 'ID',\n",
       " 'Source',\n",
       " 'Location Source',\n",
       " 'Magnitude Source',\n",
       " 'Status']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols_list=['date', # Create list for new column names to assign to dict\n",
    "              'time',\n",
    "              'lat',\n",
    "              'long',\n",
    "              'type',\n",
    "              'depth',\n",
    "              'dep_err',\n",
    "              'dep_seis_stns',\n",
    "              'mag',\n",
    "              'mag_type',\n",
    "              'mag_error',\n",
    "              'mag_seis_stns',\n",
    "              'hor_distance',\n",
    "              'hor_err',\n",
    "              'rms',\n",
    "              'id',\n",
    "              'source',\n",
    "              'loc_source',\n",
    "              'mag_source',\n",
    "              'status'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(cols))\n",
    "print(len(new_cols_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols=dict(zip(cols,new_cols_list)) # Zip 'cols' & 'new_cols_list' into new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns=new_cols) # Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'time', 'lat', 'long', 'type', 'depth', 'dep_err',\n",
       "       'dep_seis_stns', 'mag', 'mag_type', 'mag_error', 'mag_seis_stns',\n",
       "       'hor_distance', 'hor_err', 'rms', 'id', 'source', 'loc_source',\n",
       "       'mag_source', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # Check column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23412, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # Check number of columns (should be 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export df\n",
    "\n",
    "df.to_csv(os.path.join(path,'Prepared Data','2021-07-16--15:39-wrangled_subset'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _-- B) Data Consistency Checks_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mag_type\n"
     ]
    }
   ],
   "source": [
    "## Check for data type inconsistencies\n",
    "\n",
    "for col in df.columns.tolist():\n",
    "  weird = (df[[col]].applymap(type) != df[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "  if len (df[weird]) > 0:\n",
    "    print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     23409\n",
       "unique       10\n",
       "top          MW\n",
       "freq       7722\n",
       "Name: mag_type, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mag_type'].describe() # What's in 'mag_type'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mag_type']=df['mag_type'].astype('str') # Convert 'mag_type' to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double-check for data type inconsistencies\n",
    "\n",
    "for col in df.columns.tolist():\n",
    "  weird = (df[[col]].applymap(type) != df[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "  if len (df[weird]) > 0:\n",
    "    print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 0\n",
       "time                 0\n",
       "lat                  0\n",
       "long                 0\n",
       "type                 0\n",
       "depth                0\n",
       "dep_err          18951\n",
       "dep_seis_stns    16315\n",
       "mag                  0\n",
       "mag_type             0\n",
       "mag_error        23085\n",
       "mag_seis_stns    20848\n",
       "hor_distance     21808\n",
       "hor_err          22256\n",
       "rms               6060\n",
       "id                   0\n",
       "source               0\n",
       "loc_source           0\n",
       "mag_source           0\n",
       "status               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find null values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23412, 20)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "18951/23412 \n",
    "\n",
    "# Null 'dep_err' makes up 80% of dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6060/23412\n",
    "\n",
    "# 1/4 of all rows contain null 'rms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove columns with missing values. Not necessary for analysis\n",
    "\n",
    "len(df.columns) # Get number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'time',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'type',\n",
       " 'depth',\n",
       " 'dep_err',\n",
       " 'dep_seis_stns',\n",
       " 'mag',\n",
       " 'mag_type',\n",
       " 'mag_error',\n",
       " 'mag_seis_stns',\n",
       " 'hor_distance',\n",
       " 'hor_err',\n",
       " 'rms',\n",
       " 'id',\n",
       " 'source',\n",
       " 'loc_source',\n",
       " 'mag_source',\n",
       " 'status']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=df.columns.to_list() # Assign columns to 'cols'\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols=['dep_err',\n",
    "            'dep_seis_stns',\n",
    "            'mag_error',\n",
    "            'mag_seis_stns',\n",
    "            'hor_distance',\n",
    "            'hor_err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=remove_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns) # Get number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>type</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>mag_type</th>\n",
       "      <th>rms</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>loc_source</th>\n",
       "      <th>mag_source</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, time, lat, long, type, depth, mag, mag_type, rms, id, source, loc_source, mag_source, status]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find full duplicates\n",
    "\n",
    "df[df.duplicated()]\n",
    "\n",
    "# No duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export df\n",
    "\n",
    "df.to_csv(os.path.join(path,'Prepared Data','2021-07-16--16:43 - consistent'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare columns to import to new Data Profile\n",
    "# Import latest df\n",
    "\n",
    "df=pd.read_csv(os.path.join(path,'Prepared Data','2021-07-16--16:43 - consistent'),\n",
    "                index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>type</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>mag_type</th>\n",
       "      <th>rms</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>loc_source</th>\n",
       "      <th>mag_source</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/02/1965</td>\n",
       "      <td>13:44:18</td>\n",
       "      <td>19.246</td>\n",
       "      <td>145.616</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>131.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860706</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/04/1965</td>\n",
       "      <td>11:29:49</td>\n",
       "      <td>1.863</td>\n",
       "      <td>127.352</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860737</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/05/1965</td>\n",
       "      <td>18:05:58</td>\n",
       "      <td>-20.579</td>\n",
       "      <td>-173.972</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>MW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860762</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/08/1965</td>\n",
       "      <td>18:49:43</td>\n",
       "      <td>-59.076</td>\n",
       "      <td>-23.557</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860856</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/09/1965</td>\n",
       "      <td>13:32:50</td>\n",
       "      <td>11.938</td>\n",
       "      <td>126.427</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860890</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time     lat     long        type  depth  mag mag_type  \\\n",
       "0  01/02/1965  13:44:18  19.246  145.616  Earthquake  131.6  6.0       MW   \n",
       "1  01/04/1965  11:29:49   1.863  127.352  Earthquake   80.0  5.8       MW   \n",
       "2  01/05/1965  18:05:58 -20.579 -173.972  Earthquake   20.0  6.2       MW   \n",
       "3  01/08/1965  18:49:43 -59.076  -23.557  Earthquake   15.0  5.8       MW   \n",
       "4  01/09/1965  13:32:50  11.938  126.427  Earthquake   15.0  5.8       MW   \n",
       "\n",
       "   rms            id  source loc_source mag_source     status  \n",
       "0  NaN  ISCGEM860706  ISCGEM     ISCGEM     ISCGEM  Automatic  \n",
       "1  NaN  ISCGEM860737  ISCGEM     ISCGEM     ISCGEM  Automatic  \n",
       "2  NaN  ISCGEM860762  ISCGEM     ISCGEM     ISCGEM  Automatic  \n",
       "3  NaN  ISCGEM860856  ISCGEM     ISCGEM     ISCGEM  Automatic  \n",
       "4  NaN  ISCGEM860890  ISCGEM     ISCGEM     ISCGEM  Automatic  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Check df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_df=pd.DataFrame(df.columns) # Assign column names to cols_df for Data Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_df.to_clipboard() # Copy to clipboard and paste to Data Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MW     7722\n",
       "MWC    5669\n",
       "MB     3761\n",
       "MWB    2458\n",
       "MWW    1983\n",
       "MS     1702\n",
       "ML       77\n",
       "MWR      26\n",
       "MD        6\n",
       "MH        5\n",
       "Name: mag_type, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Consistency Checks from Data Profile\n",
    "\n",
    "df['mag_type'].value_counts() # Inspect 'mag_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert 'mag_type' value 'MWW' to 'MW'\n",
    "\n",
    "mag_type_series=df['mag_type'] # Create series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_type_series=mag_type_series.replace('MWW','MW') # Consolidate 'MWW' to 'MW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MW     9705\n",
       "MWC    5669\n",
       "MB     3761\n",
       "MWB    2458\n",
       "MS     1702\n",
       "ML       77\n",
       "MWR      26\n",
       "MD        6\n",
       "MH        5\n",
       "Name: mag_type, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_type_series.value_counts() # Check 'MW' count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mag_type']=mag_type_series # Replace 'mag_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MW     9705\n",
       "MWC    5669\n",
       "MB     3761\n",
       "MWB    2458\n",
       "MS     1702\n",
       "ML       77\n",
       "MWR      26\n",
       "MD        6\n",
       "MH        5\n",
       "Name: mag_type, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mag_type'].value_counts() # Check 'mag_type' count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US           20630\n",
       "ISCGEM        2460\n",
       "ISCGEMSUP      120\n",
       "CI              61\n",
       "GCMT            55\n",
       "NC              51\n",
       "AK              12\n",
       "OFFICIAL         8\n",
       "UW               6\n",
       "NN               4\n",
       "ATLAS            3\n",
       "SE               1\n",
       "PR               1\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts() # Inspect 'source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace 'ISCGEMSUP' with 'ISCGEM'\n",
    "\n",
    "source_series=df['source'] # Create series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_series=source_series.replace('ISCGEMSUP','ISCGEM') # Consolidate 'ISCGEMSUP' to 'ISCGEM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US          20630\n",
       "ISCGEM       2580\n",
       "CI             61\n",
       "GCMT           55\n",
       "NC             51\n",
       "AK             12\n",
       "OFFICIAL        8\n",
       "UW              6\n",
       "NN              4\n",
       "ATLAS           3\n",
       "SE              1\n",
       "PR              1\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_series.value_counts() # Check 'ISCGEM' count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source']=source_series # Replace 'source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US          20630\n",
       "ISCGEM       2580\n",
       "CI             61\n",
       "GCMT           55\n",
       "NC             51\n",
       "AK             12\n",
       "OFFICIAL        8\n",
       "UW              6\n",
       "NN              4\n",
       "ATLAS           3\n",
       "SE              1\n",
       "PR              1\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts() # Check 'source' count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23412, 14)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Delete 'OFFICIAL', 'NN', 'SE'\n",
    "\n",
    "df.shape # Check row count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.source!='OFFICIAL'] # Reassign all values except 'OFFICIAL', 'NN', 'SE' to df\n",
    "df=df[df.source!='NN']\n",
    "df=df[df.source!='SE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23399, 14)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # Check row count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US        20630\n",
       "ISCGEM     2580\n",
       "CI           61\n",
       "GCMT         55\n",
       "NC           51\n",
       "AK           12\n",
       "UW            6\n",
       "ATLAS         3\n",
       "PR            1\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts() # Check 'source' count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loc_source'].value_counts() # Inspect 'loc_source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mag_source'].value_counts() # Inspect 'mag_source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=df.drop(columns=['loc_source', # Drop 'loc_source' & 'mag_source'\n",
    "                    'mag_source']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23399, 12)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # Check number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export df\n",
    "\n",
    "df.to_csv(os.path.join(path,'Prepared Data','2021-07-16--16:43 - consistent'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
